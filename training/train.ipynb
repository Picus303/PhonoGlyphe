{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Transformer, build_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO YOUR OWN TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: Transformer = build_transformer(\n",
    "\tdropout = 0.2,\n",
    "\tsource_vocab_size = 58, target_vocab_size = 49, context_length = 20,\n",
    "\tencoder_block_count = 8, decoder_block_count = 3,\n",
    "\tencoder_self_attention_head_count = 4, decoder_self_attention_head_count = 4,\n",
    "\tdecoder_cross_attention_head_count = 4,\n",
    "\tencoder_self_attention_abstraction_coef = 0.25, decoder_self_attention_abstraction_coef = 0.25,\n",
    "\tdecoder_cross_attention_abstraction_coef = 0.25,\n",
    "\tencoder_feed_forward_abstraction_coef = 2.0, decoder_feed_forward_abstraction_coef = 2.0,\n",
    "\tdim = 256, epsilon = 1e-9,\n",
    ")\n",
    "\n",
    "parameters = model.parameters()\n",
    "parameter_count = sum(p.numel() for p in parameters)\n",
    "print(f\"Parameters : {parameter_count}\")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "\t\"batch_size\": 1024,\n",
    "\t\"context_length\": 20,\n",
    "\t\"learning_rate\": 1e-4,\n",
    "\t\"weight_decay\": 1e-3,\n",
    "\t\"label_smoothing\": 0.1,\n",
    "\t\"num_epochs\": 40,\n",
    "\t\"model_folder\": \"save/\",\n",
    "\t\"model_file\": \"g2p_model_\",\n",
    "\t\"model_save_interval\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare masks for attention\n",
    "masks = torch.ones((info[\"context_length\"], 1, info[\"context_length\"], info[\"context_length\"]), device=\"cuda\")\n",
    "for i in range(info[\"context_length\"]-1):\n",
    "\tmasks[i, :, :, i+1:] = 0\n",
    "\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x_enc_path, x_dec_path, l_enc_path, l_dec_path, y_dec_path):\n",
    "\t\t# Load in mmap mode in save vram\n",
    "\t\tself.X_enc = np.load(x_enc_path, mmap_mode='r')\n",
    "\t\tself.X_dec = np.load(x_dec_path, mmap_mode='r')\n",
    "\t\tself.L_enc = np.load(l_enc_path, mmap_mode='r')\n",
    "\t\tself.L_dec = np.load(l_dec_path, mmap_mode='r')\n",
    "\t\tself.Y_dec = np.load(y_dec_path, mmap_mode='r')\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.X_enc.shape[0]\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tx_enc = self.X_enc[idx]\n",
    "\t\tx_dec = self.X_dec[idx]\n",
    "\t\tl_enc = self.L_enc[idx]\n",
    "\t\tl_dec = self.L_dec[idx]\n",
    "\t\ty_dec = self.Y_dec[idx]\n",
    "\n",
    "\t\t# Convert to tensor\n",
    "\t\tx_enc = torch.tensor(x_enc, dtype=torch.int)\n",
    "\t\tx_dec = torch.tensor(x_dec, dtype=torch.int)\n",
    "\t\tl_enc = torch.tensor(l_enc, dtype=torch.int)\n",
    "\t\tl_dec = torch.tensor(l_dec, dtype=torch.int)\n",
    "\t\ty_dec = torch.tensor(y_dec, dtype=torch.float32)\n",
    "\n",
    "\t\treturn x_enc, x_dec, l_enc, l_dec, y_dec\n",
    "\n",
    "# Make the dataset\n",
    "dataset = CustomDataset(\n",
    "\tx_enc_path=\"data/X_enc.npy\",\n",
    "\tx_dec_path=\"data/X_dec.npy\",\n",
    "\tl_enc_path=\"data/L_enc.npy\",\n",
    "\tl_dec_path=\"data/L_dec.npy\",\n",
    "\ty_dec_path=\"data/Y_dec.npy\"\n",
    ")\n",
    "\n",
    "# Make the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=info[\"batch_size\"], shuffle=True, num_workers=16, pin_memory=True, pin_memory_device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=info[\"learning_rate\"], weight_decay=info[\"weight_decay\"])\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=info[\"label_smoothing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward\n",
    "x_enc, x_dec, l_enc, l_dec, y_dec = next(iter(dataloader))\n",
    "\n",
    "# Send data to GPU\n",
    "x_enc = x_enc.to(\"cuda\")\n",
    "x_dec = x_dec.to(\"cuda\")\n",
    "l_enc = l_enc.to(\"cuda\")\n",
    "l_dec = l_dec.to(\"cuda\")\n",
    "y_dec = y_dec.to(\"cuda\")\n",
    "\n",
    "# Select the masks for attention\n",
    "mask_enc = masks[l_enc[:, 0] - 1]\n",
    "mask_dec = masks[l_dec[:, 0] - 1]\n",
    "\n",
    "# Forward pass\n",
    "encoder_output = model.encode(x_enc, mask_enc)\n",
    "decoder_output = model.decode(x_dec, encoder_output, mask_dec)\n",
    "model_output = model.project(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from a checkpoint (resume training)\n",
    "pre_training_epoch = 0\n",
    "if pre_training_epoch > 0:\n",
    "\tmodel.load_state_dict(torch.load(f\"{info['model_folder']}{info['model_file']}{pre_training_epoch}.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "if os.path.exists(info[\"model_folder\"]) == False:\n",
    "\tos.makedirs(info[\"model_folder\"])\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(info[\"num_epochs\"]):\n",
    "\tmodel.train()\n",
    "\tepoch_loss = 0.0\n",
    "\tepoch_accuracy = 0.0\n",
    "\n",
    "\tbatch_iterator = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{info['num_epochs']}\")\n",
    "\tfor x_enc, x_dec, l_enc, l_dec, y_dec in batch_iterator:\n",
    "\t\t# Send data to GPU\n",
    "\t\tx_enc = x_enc.to(\"cuda\", non_blocking=True)\n",
    "\t\tx_dec = x_dec.to(\"cuda\", non_blocking=True)\n",
    "\t\tl_enc = l_enc.to(\"cuda\", non_blocking=True)\n",
    "\t\tl_dec = l_dec.to(\"cuda\", non_blocking=True)\n",
    "\t\ty_dec = y_dec.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "\t\t# Select the masks for attention\n",
    "\t\tmask_enc = masks[l_enc[:, 0] - 1]\n",
    "\t\tmask_dec = masks[l_dec[:, 0] - 1]\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\tencoder_output = model.encode(x_enc, mask_enc)\n",
    "\t\tdecoder_output = model.decode(x_dec, encoder_output, mask_dec)\n",
    "\t\tmodel_output = model.project(decoder_output)\n",
    "\n",
    "\t\t# Compute the loss\n",
    "\t\tloss = criterion(model_output, y_dec)\n",
    "\t\tepoch_loss += loss.item()\n",
    "\n",
    "\t\t# Compute the accuracy\n",
    "\t\taccuracy = (model_output.argmax(dim=-1) == y_dec.argmax(dim=-1)).sum().item() / y_dec.size(0)\n",
    "\t\tepoch_accuracy += accuracy\n",
    "\n",
    "\t\t# Optimisation\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# Display the results\n",
    "\t\tbatch_iterator.set_postfix({\"loss\": loss.item(), \"accuracy\": accuracy})\n",
    "\n",
    "\t# Display the results\n",
    "\tepoch_loss /= len(dataloader)\n",
    "\tepoch_accuracy /= len(dataloader)\n",
    "\tlosses.append(epoch_loss)\n",
    "\taccuracies.append(epoch_accuracy)\n",
    "\tprint(f\"Epoch {epoch+1}/{info['num_epochs']} : loss = {epoch_loss:.4f}, accuracy = {epoch_accuracy:.4f}\")\n",
    "\n",
    "\t# Save the model\n",
    "\tif (epoch+1) % info[\"model_save_interval\"] == 0:\n",
    "\t\ttorch.save(model.state_dict(), f\"{info['model_folder']}{info['model_file']}{epoch+pre_training_epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "epoch_loss = 0.0\n",
    "epoch_accuracy = 0.0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "batch_iterator = tqdm(dataloader, desc=\"Evaluation\")\n",
    "for x_enc, x_dec, l_enc, l_dec, y_dec in batch_iterator:\n",
    "\t# Send data to GPU\n",
    "\tx_enc = x_enc.to(\"cuda\", non_blocking=True)\n",
    "\tx_dec = x_dec.to(\"cuda\", non_blocking=True)\n",
    "\tl_enc = l_enc.to(\"cuda\", non_blocking=True)\n",
    "\tl_dec = l_dec.to(\"cuda\", non_blocking=True)\n",
    "\ty_dec = y_dec.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "\t# Select the masks for attention\n",
    "\tmask_enc = masks[l_enc[:, 0] - 1]\n",
    "\tmask_dec = masks[l_dec[:, 0] - 1]\n",
    "\n",
    "\t# Forward pass\n",
    "\tencoder_output = model.encode(x_enc, mask_enc)\n",
    "\tdecoder_output = model.decode(x_dec, encoder_output, mask_dec)\n",
    "\tmodel_output = model.project(decoder_output)\n",
    "\n",
    "\t# Compute the loss\n",
    "\tloss = criterion(model_output, y_dec)\n",
    "\tepoch_loss += loss.item()\n",
    "\n",
    "\t# Compute the accuracy\n",
    "\taccuracy = (model_output.argmax(dim=-1) == y_dec.argmax(dim=-1)).sum().item() / y_dec.size(0)\n",
    "\tepoch_accuracy += accuracy\n",
    "\n",
    "\t# Display the results\n",
    "\tbatch_iterator.set_postfix({\"loss\": loss.item(), \"accuracy\": accuracy})\n",
    "\n",
    "# Display the results\n",
    "epoch_loss /= len(dataloader)\n",
    "epoch_accuracy /= len(dataloader)\n",
    "print(f\"Evaluation : loss = {epoch_loss:.4f}, accuracy = {epoch_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
